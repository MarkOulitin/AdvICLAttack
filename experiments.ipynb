{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mark\\anaconda3\\envs\\cyber\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "textattack: Updating TextAttack package dependencies.\n",
      "textattack: Downloading NLTK required packages.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Mark\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Mark\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw to\n",
      "[nltk_data]     C:\\Users\\Mark\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\Mark\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Mark\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Mark\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "text_attack_cache_dir = os.path.join(os.getcwd(), 'text-attack')\n",
    "os.environ['TA_CACHE_DIR'] = text_attack_cache_dir\n",
    "if not os.path.isdir(text_attack_cache_dir):\n",
    "    os.mkdir(text_attack_cache_dir)\n",
    "from datasets import load_dataset\n",
    "from textattack.attack_recipes.textbugger_li_2018 import TextBuggerLi2018\n",
    "from textattack.models.wrappers.huggingface_model_wrapper import HuggingFaceModelWrapper\n",
    "from textattack.models.wrappers.model_wrapper import ModelWrapper\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from typing import List, Tuple\n",
    "from textattack import Attack\n",
    "from textattack.constraints.pre_transformation import (\n",
    "    RepeatModification,\n",
    "    StopwordModification,\n",
    ")\n",
    "from textattack.constraints.semantics.sentence_encoders import UniversalSentenceEncoder\n",
    "from textattack.goal_functions import UntargetedClassification\n",
    "from textattack.search_methods import GreedyWordSwapWIR\n",
    "from textattack.transformations import (\n",
    "    Transformation,\n",
    "    CompositeTransformation,\n",
    "    WordSwapEmbedding,\n",
    "    WordSwapHomoglyphSwap,\n",
    "    WordSwapNeighboringCharacterSwap,\n",
    "    WordSwapRandomCharacterDeletion,\n",
    "    WordSwapRandomCharacterInsertion,\n",
    ")\n",
    "from textattack.attack_recipes import AttackRecipe\n",
    "from textattack.constraints import Constraint\n",
    "import utils\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.98s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"huggyllama/llama-7b\", cache_dir=\"./models\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"huggyllama/llama-7b\", cache_dir=\"./models\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICLConstraint(Constraint):\n",
    "\n",
    "    def __init__(self, pattern):\n",
    "        super().__init__(compare_against_original=True)\n",
    "        self._pattern = pattern\n",
    "\n",
    "    def _check_constraint(self, transformed_text, reference_text) -> bool:\n",
    "        reference_matches = re.findall(self._pattern, reference_text)\n",
    "        if reference_matches:\n",
    "            last_match_reference = reference_matches[-1]\n",
    "            start_index_reference = reference_text.rindex(last_match_reference)\n",
    "            \n",
    "            transformed_matches = re.findall(self._pattern, transformed_text)\n",
    "            if transformed_matches:\n",
    "                last_match_transformed = transformed_matches[-1]\n",
    "                start_index_transformed = transformed_text.rindex(last_match_transformed)\n",
    "                \n",
    "                # return true if the suffix is the same\n",
    "                return transformed_text[start_index_transformed:] == reference_text[start_index_reference:]\n",
    "            else:\n",
    "                # no match in transformed text\n",
    "                return False\n",
    "        else:\n",
    "            # no match in reference text\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICLTextBugger(AttackRecipe):\n",
    "    @staticmethod\n",
    "    def build(model_wrapper, pattern):\n",
    "        transformation = CompositeTransformation([\n",
    "            WordSwapRandomCharacterInsertion(\n",
    "                random_one=True,\n",
    "                letters_to_insert=\" \",\n",
    "                skip_first_char=True,\n",
    "                skip_last_char=True,\n",
    "            ),\n",
    "            WordSwapRandomCharacterDeletion(\n",
    "                random_one=True, skip_first_char=True, skip_last_char=True\n",
    "            ),\n",
    "            WordSwapNeighboringCharacterSwap(\n",
    "                random_one=True, skip_first_char=True, skip_last_char=True\n",
    "            ),\n",
    "            WordSwapHomoglyphSwap(),\n",
    "            WordSwapEmbedding(max_candidates=5),\n",
    "        ])\n",
    "        constraints = [\n",
    "            RepeatModification(),\n",
    "            StopwordModification(),\n",
    "            UniversalSentenceEncoder(threshold=0.8),\n",
    "            ICLConstraint(pattern),\n",
    "        ]\n",
    "        goal_function = UntargetedClassification(model_wrapper)\n",
    "        search_method = GreedyWordSwapWIR(wir_method=\"delete\")\n",
    "        \n",
    "        return Attack(goal_function, constraints, transformation, search_method)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset sst2 (d:/Cyber-final-project/data/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n",
      "100%|██████████| 3/3 [00:00<00:00, 746.98it/s]\n"
     ]
    }
   ],
   "source": [
    "sst2_dataset = load_dataset(\"sst2\", cache_dir=\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Template:\n",
    "    def __init__(self, template: str, instruction: str) -> None:\n",
    "        if '{example}' not in template:\n",
    "            raise Exception('example placeholder not in template')\n",
    "        if '{label}' not in template:\n",
    "            raise Exception('label placeholder not in template')\n",
    "        self.template: str = template\n",
    "        self.instruction: str = instruction\n",
    "    \n",
    "    def apply(self, examples: List[str], labels: List[str]) -> str:\n",
    "        accumulator = []\n",
    "        for example, label in zip(examples, labels): \n",
    "            accumulator.append(\n",
    "                self.template.format(\n",
    "                    example=example,\n",
    "                    label=label\n",
    "                )\n",
    "            )\n",
    "        return f'{self.instruction}\\n\\n' + '\\n'.join(accumulator)\n",
    "\n",
    "class ICLSample:\n",
    "\n",
    "    def __init__(self, examples: List[str], labels: List[str], template: Template, test_sample: str) -> None:\n",
    "        if len(examples) != len(labels):\n",
    "            raise Exception('examples and labels length are not the same')\n",
    "        self.examples: List[str] = examples\n",
    "        self.labels: List[str] = labels\n",
    "        self.test_sample: str = test_sample\n",
    "        self.template: Template = template\n",
    "\n",
    "    def to_text(self) -> str:\n",
    "        examples = self.examples + [self.test_sample]\n",
    "        labels = self.labels + ['_']\n",
    "        return self.template.apply(examples, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list_into_chunks(array: list, chunk_size: int):\n",
    "    chunks = []\n",
    "    for i in range(0, len(array), chunk_size):\n",
    "        chunk = array[i:i+chunk_size]\n",
    "        chunks.append(chunk)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst2_config = {\n",
    "    'pattern': r\"Review: .+?\\nSentiment: .+?\",\n",
    "    'template': \"\"\"Review: {example}\n",
    "Sentiment: {label}\"\"\",\n",
    "    'instruction': 'Choose sentiment from Positive or Negative .',\n",
    "}\n",
    "\n",
    "def sst2ICL_sample_factory(n_examples: int) -> List[ICLSample]:\n",
    "    sst2_template = Template(sst2_config['template'], sst2_config['instruction'])\n",
    "    records = []\n",
    "    # aggregate all records\n",
    "    for record in sst2_dataset['train']:\n",
    "        records.append({\n",
    "            'sentence': record['sentence'],\n",
    "            'label': 'Positive' if record['label'] == 1 else 'Negative',\n",
    "        })\n",
    "    for record in sst2_dataset['validation']:\n",
    "        records.append({\n",
    "            'sentence': record['sentence'],\n",
    "            'label': 'Positive' if record['label'] == 1 else 'Negative',\n",
    "        })\n",
    "    chunks = split_list_into_chunks(records, n_examples)\n",
    "    samples: List[ICLSample] = []\n",
    "    ground_truth: List[str] = []\n",
    "    for chunk in chunks:\n",
    "        examples = [example['sentence'] for example in chunk[:-1]]\n",
    "        labels = [example['label'] for example in chunk[:-1]]\n",
    "        test_sample = chunk[-1]['sentence']\n",
    "        ground_truth.append(chunk[-1]['label'])\n",
    "        sample: ICLSample = ICLSample(examples, labels, sst2_template, test_sample)\n",
    "        samples.append(sample)\n",
    "    return samples, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_data = sst2ICL_sample_factory(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset trec (d:/Cyber-final-project/data/trec/default/2.0.0/f2469cab1b5fceec7249fda55360dfdbd92a7a5b545e91ea0f78ad108ffac1c2)\n",
      "100%|██████████| 2/2 [00:00<00:00, 401.25it/s]\n"
     ]
    }
   ],
   "source": [
    "trec_dataset = load_dataset(\"trec\", cache_dir=\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_config = {\n",
    "    'pattern': r\"Question: .+?\\nAnswer: .+?\",\n",
    "    'template': \"\"\"Question: {example}\n",
    "Answer: {label}\"\"\",\n",
    "    'instruction': 'Classify the questions based on whether their answer type is a Number, Location, Person, Description, Entity, or Abbreviation.\\n',\n",
    "}\n",
    "\n",
    "def trecICL_sample_factory(n_examples: int) -> List[ICLSample]:\n",
    "    trec_template = Template(trec_config['template'], trec_config['instruction'])\n",
    "    numeric_label_2_textual = {\n",
    "        0: 'Abbreviation',\n",
    "        1: 'Entity',\n",
    "        2: 'Description',\n",
    "        3: 'Person',\n",
    "        4: 'Location',\n",
    "        5: 'Number',\n",
    "    }\n",
    "    records = []\n",
    "    # aggregate all records\n",
    "    for record in trec_dataset['train']:\n",
    "        records.append({\n",
    "            'text': record['text'],\n",
    "            'label': numeric_label_2_textual[record['coarse_label']],\n",
    "        })\n",
    "    for record in trec_dataset['test']:\n",
    "        records.append({\n",
    "            'text': record['text'],\n",
    "            'label': numeric_label_2_textual[record['coarse_label']],\n",
    "        })\n",
    "    chunks = split_list_into_chunks(records, n_examples)\n",
    "    samples: List[ICLSample] = []\n",
    "    ground_truth: List[str] = []\n",
    "    for chunk in chunks:\n",
    "        examples = [example['text'] for example in chunk[:-1]]\n",
    "        labels = [example['label'] for example in chunk[:-1]]\n",
    "        test_sample = chunk[-1]['text']\n",
    "        ground_truth.append(chunk[-1]['label'])\n",
    "        sample: ICLSample = ICLSample(examples, labels, trec_template, test_sample)\n",
    "        samples.append(sample)\n",
    "    return samples, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_data = trecICL_sample_factory(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: Unknown if model of class <class 'transformers.models.llama.modeling_llama.LlamaForCausalLM'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
     ]
    }
   ],
   "source": [
    "# why?\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "huggingface_model = HuggingFaceModelWrapper(model=model, tokenizer=tokenizer)\n",
    "attack = ICLTextBugger.build(huggingface_model, sst2_config['pattern'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_samples, sst_labels = sst_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LlamaForCausalLM.forward() got an unexpected keyword argument 'token_type_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m attack\u001b[39m.\u001b[39;49mattack(sst_samples[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mto_text(), sst_labels[\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\Mark\\anaconda3\\envs\\cyber\\lib\\site-packages\\textattack\\attack.py:442\u001b[0m, in \u001b[0;36mAttack.attack\u001b[1;34m(self, example, ground_truth_output)\u001b[0m\n\u001b[0;32m    437\u001b[0m     example \u001b[39m=\u001b[39m AttackedText(example)\n\u001b[0;32m    439\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[0;32m    440\u001b[0m     ground_truth_output, (\u001b[39mint\u001b[39m, \u001b[39mstr\u001b[39m)\n\u001b[0;32m    441\u001b[0m ), \u001b[39m\"\u001b[39m\u001b[39m`ground_truth_output` must either be `str` or `int`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 442\u001b[0m goal_function_result, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgoal_function\u001b[39m.\u001b[39;49minit_attack_example(\n\u001b[0;32m    443\u001b[0m     example, ground_truth_output\n\u001b[0;32m    444\u001b[0m )\n\u001b[0;32m    445\u001b[0m \u001b[39mif\u001b[39;00m goal_function_result\u001b[39m.\u001b[39mgoal_status \u001b[39m==\u001b[39m GoalFunctionResultStatus\u001b[39m.\u001b[39mSKIPPED:\n\u001b[0;32m    446\u001b[0m     \u001b[39mreturn\u001b[39;00m SkippedAttackResult(goal_function_result)\n",
      "File \u001b[1;32mc:\\Users\\Mark\\anaconda3\\envs\\cyber\\lib\\site-packages\\textattack\\goal_functions\\goal_function.py:68\u001b[0m, in \u001b[0;36mGoalFunction.init_attack_example\u001b[1;34m(self, attacked_text, ground_truth_output)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mground_truth_output \u001b[39m=\u001b[39m ground_truth_output\n\u001b[0;32m     67\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_queries \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 68\u001b[0m result, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_result(attacked_text, check_skip\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     69\u001b[0m \u001b[39mreturn\u001b[39;00m result, _\n",
      "File \u001b[1;32mc:\\Users\\Mark\\anaconda3\\envs\\cyber\\lib\\site-packages\\textattack\\goal_functions\\goal_function.py:79\u001b[0m, in \u001b[0;36mGoalFunction.get_result\u001b[1;34m(self, attacked_text, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_result\u001b[39m(\u001b[39mself\u001b[39m, attacked_text, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     77\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"A helper method that queries ``self.get_results`` with a single\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[39m    ``AttackedText`` object.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m     results, search_over \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_results([attacked_text], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     80\u001b[0m     result \u001b[39m=\u001b[39m results[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(results) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     \u001b[39mreturn\u001b[39;00m result, search_over\n",
      "File \u001b[1;32mc:\\Users\\Mark\\anaconda3\\envs\\cyber\\lib\\site-packages\\textattack\\goal_functions\\goal_function.py:96\u001b[0m, in \u001b[0;36mGoalFunction.get_results\u001b[1;34m(self, attacked_text_list, check_skip)\u001b[0m\n\u001b[0;32m     94\u001b[0m     attacked_text_list \u001b[39m=\u001b[39m attacked_text_list[:queries_left]\n\u001b[0;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_queries \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(attacked_text_list)\n\u001b[1;32m---> 96\u001b[0m model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_model(attacked_text_list)\n\u001b[0;32m     97\u001b[0m \u001b[39mfor\u001b[39;00m attacked_text, raw_output \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(attacked_text_list, model_outputs):\n\u001b[0;32m     98\u001b[0m     displayed_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_displayed_output(raw_output)\n",
      "File \u001b[1;32mc:\\Users\\Mark\\anaconda3\\envs\\cyber\\lib\\site-packages\\textattack\\goal_functions\\goal_function.py:216\u001b[0m, in \u001b[0;36mGoalFunction._call_model\u001b[1;34m(self, attacked_text_list)\u001b[0m\n\u001b[0;32m    210\u001b[0m         uncached_list\u001b[39m.\u001b[39mappend(text)\n\u001b[0;32m    211\u001b[0m uncached_list \u001b[39m=\u001b[39m [\n\u001b[0;32m    212\u001b[0m     text\n\u001b[0;32m    213\u001b[0m     \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m attacked_text_list\n\u001b[0;32m    214\u001b[0m     \u001b[39mif\u001b[39;00m text \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_model_cache\n\u001b[0;32m    215\u001b[0m ]\n\u001b[1;32m--> 216\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_model_uncached(uncached_list)\n\u001b[0;32m    217\u001b[0m \u001b[39mfor\u001b[39;00m text, output \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(uncached_list, outputs):\n\u001b[0;32m    218\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_model_cache[text] \u001b[39m=\u001b[39m output\n",
      "File \u001b[1;32mc:\\Users\\Mark\\anaconda3\\envs\\cyber\\lib\\site-packages\\textattack\\goal_functions\\goal_function.py:165\u001b[0m, in \u001b[0;36mGoalFunction._call_model_uncached\u001b[1;34m(self, attacked_text_list)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[39mwhile\u001b[39;00m i \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(inputs):\n\u001b[0;32m    164\u001b[0m     batch \u001b[39m=\u001b[39m inputs[i : i \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size]\n\u001b[1;32m--> 165\u001b[0m     batch_preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(batch)\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Some seq-to-seq models will return a single string as a prediction\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# for a single-string list. Wrap these in a list.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(batch_preds, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Mark\\anaconda3\\envs\\cyber\\lib\\site-packages\\textattack\\models\\wrappers\\huggingface_model_wrapper.py:61\u001b[0m, in \u001b[0;36mHuggingFaceModelWrapper.__call__\u001b[1;34m(self, text_input_list)\u001b[0m\n\u001b[0;32m     58\u001b[0m inputs_dict\u001b[39m.\u001b[39mto(model_device)\n\u001b[0;32m     60\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> 61\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs_dict)\n\u001b[0;32m     63\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs[\u001b[39m0\u001b[39m], \u001b[39mstr\u001b[39m):\n\u001b[0;32m     64\u001b[0m     \u001b[39m# HuggingFace sequence-to-sequence models return a list of\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[39m# string predictions as output. In this case, return the full\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[39m# list of outputs.\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\Mark\\anaconda3\\envs\\cyber\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;31mTypeError\u001b[0m: LlamaForCausalLM.forward() got an unexpected keyword argument 'token_type_ids'"
     ]
    }
   ],
   "source": [
    "attack.attack(sst_samples[0].to_text(), sst_labels[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyber-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
